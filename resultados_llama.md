\subsection{Resultados}

Os resultados produzidos ao longo das etapas experimentais foram analisados de forma integrada, considerando conjuntamente os níveis N1 e N2, bem como os três experimentos definidos (EN1, EN2 e EN1N2). A comparação foi orientada pelos fundamentos teóricos da automação normativa em BIM e pelos princípios de validação semântica em Processamento de Linguagem Natural (PLN), permitindo avaliar não apenas a qualidade das saídas geradas pelo Modelo de Linguagem de Grande Porte, mas também a adequação das métricas empregadas para validar essas saídas.

Os resultados do modelo Llama foram analisados com foco na proximidade semantica entre as saidas geradas e os valores reais do dataset. As metricas utilizadas capturam complementarmente similaridade lexical (FuzzyWuzzy, TF-IDF) e semantica (SBERT, BERTimbau, Multilingual, WMD), permitindo avaliar o quanto o Llama preserva o significado normativo ao longo das etapas.

No experimento EN1, a comparação concentrou-se na proximidade semântica entre as regras N1 geradas automaticamente pelo LLM e as regras N1 reais presentes no dataset. O Llama apresentou FuzzyWuzzy 0.711, TF-IDF 0.535, SBERT 0.764, Multilingual 0.788, WMD_ft 0.674 e WMD_nilc 0.665. Esses valores indicam boa correspondencia semantica entre regras N1 geradas e regras reais, com desempenho mais elevado nas metricas de embeddings, sugerindo que o modelo captura equivalencias de significado mesmo quando ha variacoes lexicais. O tempo total de geracao foi de 5676.97 segundos (1:34:36.97).

No EN2, o experimento avalia a transformacao das regras N1 em representacoes N2 estruturadas (operadores RASE), comparando a saida gerada com o N2 real do dataset. O Llama obteve seus melhores resultados globais, com FuzzyWuzzy 0.761, TF-IDF 0.777, SBERT 0.806, Multilingual 0.869, WMD_ft 0.857 e WMD_nilc 0.806. Esses indicadores apontam elevada proximidade ao N2 real, refletindo capacidade consistente de identificar e estruturar os operadores RASE de forma alinhada ao dataset. O ganho simultaneo em metricas lexicais e semanticas sugere baixa divergencia tanto na formulacao textual quanto na estrutura logica. O tempo total de geracao foi de 6895.71 segundos (1:54:55.71).

No EN1N2, o experimento avalia um pipeline encadeado em que o N1 gerado automaticamente e utilizado como entrada para gerar o N2, e a saida final e comparada ao N2 real. O Llama manteve desempenho robusto apesar da propagacao de erros do pipeline, com FuzzyWuzzy 0.654, TF-IDF 0.492, SBERT 0.678, Multilingual 0.743, WMD_ft 0.663 e WMD_nilc 0.650. Embora haja reducao em relacao ao EN2 direto, as metricas semanticas permanecem altas, indicando que o modelo continua produzindo saidas proximas ao real mesmo quando depende de uma etapa anterior automatizada. O tempo total de geracao registrado em foi de 9450.14 segundos (2:37:30.14).

A similaridade lexical (FuzzyWuzzy e TF-IDF) mede a sobreposicao de tokens, ordem e frequencia de termos; por isso, tende a cair quando o modelo reescreve trechos com sinonimos, muda a ordem das palavras ou condensa frases. Em contraste, a similaridade semantica (SBERT e Multilingual) usa embeddings para aproximar significados mesmo com reformulacoes. O impacto disso nos valores fica evidente no EN1, em que SBERT 0.764 e Multilingual 0.788 superam TF-IDF 0.535; essa diferenca indica que o Llama preserva o sentido das regras mesmo quando a superficie textual muda. No EN2, as metricas lexicais e semanticas sobem em conjunto (FuzzyWuzzy 0.761, TF-IDF 0.777, SBERT 0.806, Multilingual 0.869), sugerindo que a representacao N2 gerada ficou mais proxima do texto real tambem em termos de vocabulario. No EN1N2, a queda mais acentuada em TF-IDF (0.492) do que em SBERT (0.678) reforca que os desvios introduzidos no pipeline afetam mais a forma lexical do que o significado, evidenciando a robustez relativa das metricas semanticas para avaliar proximidade ao real.

Quanto ao tempo de processamento, as metricas lexicais (FuzzyWuzzy e TF-IDF) tendem a ser mais leves computacionalmente, enquanto as metricas baseadas em embeddings (SBERT e Multilingual) e as de distancia semantica (WMD) demandam mais tempo devido a geracao de vetores e calculos de distancia. A execucao foi realizada em uma maquina com 13th Gen Intel(R) Core(TM) i9-13900K (3.00 GHz), 32 GB de RAM, GPU RTX 4080, sistema operacional Linux Ubuntu 22.04. Esse ambiente fornece capacidade suficiente para processar os tres experimentos com estabilidade e reduzir a latencia das metricas semanticas, embora o custo relativo entre metricas permaneça evidente. Quando necessario, o uso de GPU tende a beneficiar principalmente as etapas de embeddings, enquanto as metricas lexicais permanecem predominantemente CPU.

De forma consolidada, os resultados mostram que o Llama apresentou alta proximidade semantica ao real em todos os experimentos, com pico de desempenho em EN2 e estabilidade relativa em EN1N2. Isso evidencia que o modelo e capaz de manter coerencia normativa e estrutural, sendo particularmente eficaz na formalizacao N2 e resiliente a variacoes introduzidas no encadeamento do processo.
