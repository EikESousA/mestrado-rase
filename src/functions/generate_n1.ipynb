{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text: str) -> list:       \n",
    "    sentences = re.split(r'(?<!\\d)(\\.)\\n|\\n|(?<!\\d)(\\.)(?!\\d)', text.strip())\n",
    "    \n",
    "    processed_sentences = []\n",
    "    temp_sentence = \"\"\n",
    "    \n",
    "    for part in sentences:\n",
    "        if part is None:\n",
    "            continue\n",
    "        temp_sentence += part.strip()\n",
    "        if part.strip() == \".\":\n",
    "            processed_sentences.append(temp_sentence.strip())\n",
    "            temp_sentence = \"\"\n",
    "    \n",
    "    if temp_sentence:\n",
    "        processed_sentences.append(temp_sentence.strip())\n",
    "    \n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n1(input_path: str, output_path: str, template: str) -> None:\n",
    "    \"\"\"\n",
    "    Lê um arquivo JSON contendo textos e aplica a metodologia RASE N1, gerando um novo JSON com os textos transformados.\n",
    "\n",
    "    - Para cada entrada no JSON, o campo \"text\" é processado e dividido em sentenças menores, mantendo aplicabilidade, \n",
    "      seleção, requisito e exceção.\n",
    "    - O resultado processado é armazenado no campo \"texts\" da mesma entrada.\n",
    "    - O novo JSON é salvo no caminho especificado.\n",
    "\n",
    "    Parâmetros:\n",
    "        - input_path (str): Caminho do arquivo JSON de entrada contendo os textos a serem transformados.\n",
    "        - output_path (str): Caminho do arquivo JSON de saída onde os textos processados serão armazenados.\n",
    "        - template (str): Template utilizado para estruturar a solicitação ao modelo de linguagem.\n",
    "    \n",
    "    Exceções:\n",
    "        - FileNotFoundError: Se o arquivo de entrada não for encontrado.\n",
    "        - JSONDecodeError: Se houver erro ao decodificar o JSON de entrada.\n",
    "\n",
    "    Retorna:\n",
    "        - None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"Erro: Arquivo de entrada não encontrado.\")\n",
    "        return\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Erro: Falha ao decodificar JSON de entrada.\")\n",
    "        return\n",
    "\n",
    "    model = OllamaLLM(model=\"splitpierre/bode-alpaca-pt-br\")\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model\n",
    "\n",
    "    for item in data[\"datas\"]:\n",
    "        result = chain.invoke({\"text\": item[\"text\"]})\n",
    "        item[\"texts\"] = process_text(result)\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "A metodologia **RASE N1** transforma textos em unidades menores, onde cada unidade contém **apenas uma única regra computável** com métricas claras.  \n",
    "\n",
    "### **Instruções:**  \n",
    "1. **Divida o texto** em sentenças curtas e diretas, respeitando a metodologia **RASE N1**.  \n",
    "2. **Cada sentença deve conter somente uma única regra computável**.  \n",
    "3. **Não remova nenhum dos seguintes elementos:**  \n",
    "   - **Aplicabilidade:** Onde ou quando a regra se aplica.  \n",
    "   - **Seleção:** Elemento específico dentro da aplicabilidade.  \n",
    "   - **Requisito:** O que deve ser feito.  \n",
    "   - **Exceção:** Casos que não precisam seguir a regra.  \n",
    "4. **A resposta deve conter apenas os textos reformulados, sem explicações ou títulos.**  \n",
    "5. **Cada frase deve ser separada por `\\n`, garantindo uma quebra de linha entre elas.**  \n",
    "6. **Todas as frases devem ser convertidas em afirmações lógicas.**  \n",
    "\n",
    "### **Exemplo 1:**  \n",
    "\n",
    "#### **Entrada:**  \n",
    "\"A inclinação transversal da superfície deve ser de até 2 % para pisos internos e de até 3 % para pisos externos. A inclinação longitudinal da superfície deve ser inferior a 5 %. Inclinações iguais ou superiores a 5 % são consideradas rampas e, portanto, devem atender a 6.6.\"  \n",
    "\n",
    "#### **Saída:**  \n",
    "Pisos internos devem ter inclinação transversal de no máximo 2%.\\n  \n",
    "Pisos externos devem ter inclinação transversal de no máximo 3%.\\n  \n",
    "A inclinação longitudinal da superfície deve ser inferior a 5%.\\n  \n",
    "Inclinações iguais ou superiores a 5% são consideradas rampas e devem atender à norma 6.6.\\n  \n",
    "\n",
    "### **Exemplo 2:**  \n",
    "\n",
    "#### **Entrada:**  \n",
    "\"Os acessos devem ser vinculados através de rota acessível à circulação principal e às circulações de emergência. Os acessos devem permanecer livres de quaisquer obstáculos de forma permanente.\"  \n",
    "\n",
    "#### **Saída:**  \n",
    "Os acessos devem ser vinculados através de rota acessível à circulação principal e às circulações de emergência.\\n  \n",
    "Os acessos devem permanecer livres de quaisquer obstáculos de forma permanente.\\n  \n",
    "\n",
    "### **Agora, transforme o texto abaixo utilizando a metodologia RASE N1:**  \n",
    "\n",
    "#### **Texto:**  \n",
    "{text}  \n",
    "\n",
    "#### **Resposta:**    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file: str = \"../databases/data_n1.json\"\n",
    "output_file: str = \"../databases/generate_n1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído. Resultado salvo em ../databases/generate_n1.json\n"
     ]
    }
   ],
   "source": [
    "generate_n1(input_file, output_file, template)\n",
    "print(f\"Processamento concluído. Resultado salvo em {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
